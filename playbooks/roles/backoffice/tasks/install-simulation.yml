---
#uncomment below change for impala enablement

- name: Get Impala Module
  shell: aws s3 --region {{ region }} cp s3://{{ s3_deployment_bucket }}/{{ BuildVersion }}Impala.tar.gz /mnt/
  sudo: yes
- name: Untar Impala prebuild code
  shell: tar -zxf /mnt/Impala.tar.gz chdir=/mnt/
- name: create /mnt/local
  shell: mkdir /mnt/local
  sudo: yes
  ignore_errors: True
- name: Remove old Hive from /mnt/local
  shell: rm -rf /mnt/local/hive
  sudo: yes
  ignore_errors: True
- name: Copy over Hive to /mnt/local
  command: cp -R /mnt/Impala/thirdparty/hive-0.13.1-cdh5.3.0 /mnt/local/
  sudo: yes
- name: Rename Hive in /mnt/local
  command: mv /mnt/local/hive-0.13.1-cdh5.3.0 /mnt/local/hive
  sudo: yes
- name: Remove old Hadoop from /mnt/local
  shell: rm -rf /mnt/local/hadoop
  sudo: yes
- name: Copy over Hadoop to /mnt/local
  command: cp -R /mnt/Impala/thirdparty/hadoop-2.5.0-cdh5.3.0 /mnt/local/
  sudo: yes
- name: Rename Hadoop in /mnt/local
  command: mv /mnt/local/hadoop-2.5.0-cdh5.3.0 /mnt/local/hadoop
  sudo: yes
- name: Update easy install
  command: easy_install -U setuptools
  sudo: yes
- name: Install sasl dependency..
  command: apt-get install python-dev libsasl2-dev gcc g++
  sudo: yes
  ignore_errors: True
- name: Install sasl
  pip: name=sasl
  sudo: yes
  ignore_errors: True
- name: Install thrift
  pip: name=sasl
  sudo: yes
  ignore_errors: True
- name: Install impyla
  pip: name=impyla
  sudo: yes
  ignore_errors: True
- name: Install pyhs2
  pip: name=pyhs2
  sudo: yes
  ignore_errors: True

- name: Create a directory for Hadoop configuration files
  shell: mkdir -p /etc/hadoop/conf
  sudo: yes
- name: Create a directory for Hive configuration files
  shell: mkdir -p /etc/hive/conf
  sudo: yes
- name: Create a directory for Impala configuration files
  shell: mkdir -p /etc/impala/conf
  sudo: yes

#change permission if not accurate
- name: Update Hadoop permissions
  shell: chown -R ubuntu:root /mnt/local/hadoop
  sudo: yes
- name: Update Hive permissions
  shell: chown -R ubuntu:root /mnt/local/hive
  sudo: yes
- name: Update Hadoop daemon permission
  shell: chmod 777 /mnt/local/hadoop/sbin/hadoop-daemon.sh
  sudo: yes
- name: Update Hadoop yarn daemon permission
  shell: chmod 755 /mnt/local/hadoop/sbin/yarn-daemon.sh
  sudo: yes
- name: Update binary permissions
  shell: chmod 755 /mnt/local/hadoop/bin/hdfs
  sudo: yes
- name: Update binary permissions
  shell: chmod 755 /mnt/local/hadoop/bin/hadoop
  sudo: yes
- name: Update binary permissions
  shell: chmod 755 /mnt/local/hadoop/bin/yarn
  sudo: yes
- name: Update binary permissions
  shell: chmod 755 /mnt/local/hive/bin/hive
  sudo: yes
- name: Update root permissions
  shell: sudo chmod 555 /
  sudo: yes
- name: Create a yarn directory
  shell: mkdir -p /var/lib/hadoop-yarn
  sudo: yes
- name: Create a hadoop directory
  shell: mkdir -p /var/lib/hadoop-hdfs
  sudo: yes
- name: Update Hadoop dir permissions
  shell: chown -R ubuntu:root /var/lib/hadoop-hdfs
  sudo: yes
- name: Create a hadoop directory
  shell: mkdir -p /var/run/hadoop-hdfs
  sudo: yes
- name: Update Hadoop dir permissions
  shell: chown -R ubuntu:root /var/run/hadoop-hdfs
  sudo: yes
- name: Install mysql jar files
  shell: apt-get install libmysql-java
  sudo: yes
- name: create a symlink for mysql jar file
  shell: cp /usr/share/java/mysql-connector-java-5.1.28.jar /mnt/local/hive/lib/
  sudo: yes
- name: copy boost lib
  shell: cp /mnt/Impala/libboost_thread.so.1.46.1 /usr/lib/
  sudo: yes
- name: copy boost lib
  shell: cp /mnt/Impala/libboost_regex.so.1.46.1 /usr/lib/
  sudo: yes
- name: copy boost lib
  shell: cp /mnt/Impala/libboost_system.so.1.46.1 /usr/lib/
  sudo: yes
- name: copy boost lib
  shell: cp /mnt/Impala/libboost_filesystem.so.1.46.1 /usr/lib/
  sudo: yes
- name: copy boost lib
  shell: cp /mnt/Impala/libboost_date_time.so.1.46.1 /usr/lib/
  sudo: yes
- name: copy icui lib
  shell: cp /mnt/Impala/libicudata.so.48 /usr/lib/
  sudo: yes
- name: copy icui lib
  shell: cp /mnt/Impala/libicui18n.so.48 /usr/lib/
  sudo: yes
- name: copy icui lib
  shell: cp /mnt/Impala/libicuuc.so.48 /usr/lib/
  sudo: yes
- name: copy hdfs lib
  shell: cp /mnt/Impala/libhdfs.so.0.0.0 /usr/lib/
  sudo: yes

#mysql configuration for hive metastore
- name: Install python module for mysql
  shell: apt-get install python-mysqldb
  sudo: yes
- name: Set root password for mysql
  shell: mysqladmin -u root password mysql
  sudo: yes
  ignore_errors: True
- name: create a database metastore in mysql
  mysql_db: name=metastore login_user=root login_password=mysql state=present
- name: feed database.sql to server
  mysql_db: login_user=root login_password=mysql name=metastore state=import target=/mnt/local/hive/scripts/metastore/upgrade/mysql/hive-schema-0.13.0.mysql.sql
  sudo: yes
  ignore_errors: True
- name: create working directory for Hive
  shell: mkdir -p /var/run/hive
  sudo: yes
- name: create working directory for Hive
  shell: mkdir -p /var/log/hive
  sudo: yes
- name: Change the permission of dir
  shell: chown -R ubuntu:root /var/run/hive
  sudo: yes
- name: Change the permission of dir
  shell: chown -R ubuntu:root /var/log/hive
  sudo: yes
- name: create working directory for Impala
  shell: mkdir -p /var/run/impala
  sudo: yes
- name: Change the permission of dir
  shell: chown -R ubuntu:root /var/run/impala
  sudo: yes
- name: create working directory for Impala
  shell: mkdir -p /var/log/impala
  sudo: yes
- name: Change the permission of dir
  shell: chown -R ubuntu:root /var/log/impala
  sudo: yes

- name: Copy over Hadoop core configuration file
  command: cp /mnt/Impala/fe/src/test/resources/core-site.xml /etc/hadoop/conf/
  sudo: yes
- name: Copy over Hadoop core configuration file
  command: cp /mnt/Impala/fe/src/test/resources/core-site.xml /etc/impala/conf/
  sudo: yes
- name: Copy over Hadoop core configuration file
  command: cp /mnt/Impala/fe/src/test/resources/core-site.xml /etc/hive/conf/
  sudo: yes
- name: Copy over Hadoop core configuration file
  command: cp /mnt/Impala/fe/src/test/resources/core-site.xml /mnt/local/hadoop/etc/hadoop
  sudo: yes
- name: Copy over Hadoop hdfs configuration file
  command: cp /mnt/Impala/fe/src/test/resources/hdfs-site.xml /etc/hadoop/conf/
  sudo: yes
- name: Copy over Hadoop hdfs configuration file
  command: cp /mnt/Impala/fe/src/test/resources/hdfs-site.xml /etc/impala/conf/
  sudo: yes
- name: Copy over Hadoop hdfs configuration file
  command: cp /mnt/Impala/fe/src/test/resources/hdfs-site.xml /etc/hive/conf/
  sudo: yes
- name: Copy over Hadoop hdfs configuration file
  command: cp /mnt/Impala/fe/src/test/resources/hdfs-site.xml /mnt/local/hadoop/etc/hadoop
  sudo: yes
- name: Copy over Hadoop yarn configuration file
  command: cp /mnt/Impala/fe/src/test/resources/yarn-site.xml /etc/hadoop/conf/
  sudo: yes
- name: Copy over Hadoop yarn configuration file
  command: cp /mnt/Impala/fe/src/test/resources/yarn-site.xml /etc/impala/conf/
  sudo: yes
- name: Copy over Hadoop yarn configuration file
  command: cp /mnt/Impala/fe/src/test/resources/yarn-site.xml /etc/hive/conf/
  sudo: yes
- name: Copy over Hadoop yarn configuration file
  command: cp /mnt/Impala/fe/src/test/resources/yarn-site.xml /mnt/local/hadoop/etc/hadoop
  sudo: yes
- name: Copy over Hadoop mapred configuration file
  command: cp /mnt/Impala/fe/src/test/resources/mapred-site.xml /etc/hadoop/conf/
  sudo: yes
- name: Copy over Hadoop mapred configuration file
  command: cp /mnt/Impala/fe/src/test/resources/mapred-site.xml /etc/impala/conf/
  sudo: yes
- name: Copy over Hadoop mapred configuration file
  command: cp /mnt/Impala/fe/src/test/resources/mapred-site.xml /etc/hive/conf/
  sudo: yes
- name: Copy over Hadoop mapred configuration file
  command: cp /mnt/Impala/fe/src/test/resources/mapred-site.xml /mnt/local/hadoop/etc/hadoop
  sudo: yes
- name: Copy over Hadoop ENV file
  command: cp /mnt/Impala/fe/src/test/resources/hadoop-env.sh /etc/hadoop/conf/
  sudo: yes
- name: Copy over Hadoop ENV file
  command: cp /mnt/Impala/fe/src/test/resources/hadoop-env.sh /etc/impala/conf/
  sudo: yes
- name: Copy over Hadoop ENV file
  command: cp /mnt/Impala/fe/src/test/resources/hadoop-env.sh /etc/hive/conf/
  sudo: yes
- name: Copy over Hadoop ENV file
  command: cp /mnt/Impala/fe/src/test/resources/hadoop-env.sh /mnt/local/hadoop/etc/hadoop
  sudo: yes
- name: Copy over Hive configuration file
  command: cp /mnt/Impala/fe/src/test/resources/hive-site.xml /etc/hive/conf/
  sudo: yes
- name: Copy over Hive configuration file
  command: cp /mnt/Impala/fe/src/test/resources/hive-site.xml /etc/hadoop/conf/
  sudo: yes
- name: Copy over Hive configuration file
  command: cp /mnt/Impala/fe/src/test/resources/hive-site.xml /etc/impala/conf/
  sudo: yes
- name: Copy over Hive configuration file
  command: cp /mnt/Impala/fe/src/test/resources/hive-site.xml /mnt/local/hive/conf/
  sudo: yes
- name: Copy over Impala state store binary to /usr/bin
  command: cp /mnt/Impala/be/build/debug/statestore/statestored /usr/bin/statestored
  sudo: yes
  ignore_errors: True
- name: Copy over Impala catalog binary to /usr/bin
  command: cp /mnt/Impala/be/build/debug/catalog/catalogd /usr/bin/catalogd
  sudo: yes
  ignore_errors: True
- name: Copy over Impala server binary to /usr/bin
  command: cp /mnt/Impala/be/build/debug/service/impalad /usr/bin/impalad
  sudo: yes
  ignore_errors: True
- name: Update binary permissions
  shell: chmod 755 /usr/bin/impalad
  sudo: yes
  ignore_errors: True
- name: Copy over Impala config to /etc/default
  command: cp /mnt/Impala/impala /etc/default/
  sudo: yes
  ignore_errors: True

#copy system start up scripts
- name: Copy over System V files into /etc/init.d/
  command: cp /mnt/Impala/hadoop-hdfs-datanode /etc/init.d/hadoop-hdfs-datanode
  sudo: yes
- name: Copy over System V files into /etc/init.d/
  command: cp /mnt/Impala/hadoop-hdfs-namenode /etc/init.d/hadoop-hdfs-namenode
  sudo: yes
- name: Copy over System V files into /etc/init.d/
  command: cp /mnt/Impala/hadoop-hdfs-secondarynamenode /etc/init.d/hadoop-hdfs-secondarynamenode
  sudo: yes
- name: Copy over System V files into /etc/init.d/
  command: cp /mnt/Impala/hadoop-yarn-nodemanager /etc/init.d/hadoop-yarn-nodemanager
  sudo: yes
- name: Copy over System V files into /etc/init.d/
  command: cp /mnt/Impala/hadoop-yarn-resourcemanager /etc/init.d/hadoop-yarn-resourcemanager
  sudo: yes
- name: Copy over System V files into /etc/init.d/
  command: cp /mnt/Impala/hive-metastore /etc/init.d/hive-metastore
  sudo: yes
- name: Copy over System V files into /etc/init.d/
  command: cp /mnt/Impala/hive-server2 /etc/init.d/hive-server2
  sudo: yes
- name: Copy over System V files into /etc/init.d/
  command: cp /mnt/Impala/impala-catalog /etc/init.d/impala-catalog
  sudo: yes
- name: Copy over System V files into /etc/init.d/
  command: cp /mnt/Impala/impala-server /etc/init.d/impala-server
  sudo: yes
- name: Copy over System V files into /etc/init.d/
  command: cp /mnt/Impala/impala-state-store /etc/init.d/impala-state-store
  sudo: yes

#create a symlinks for that points to above start up script
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hadoop-hdfs-namenode S85hadoop-hdfs-namenode chdir=/etc/rc2.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hadoop-hdfs-datanode S85hadoop-hdfs-datanode chdir=/etc/rc2.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hadoop-hdfs-secondarynamenode S85hadoop-hdfs-secondarynamenode chdir=/etc/rc2.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hadoop-yarn-resourcemanager S85hadoop-yarn-resourcemanager chdir=/etc/rc2.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hadoop-yarn-nodemanager S85hadoop-yarn-nodemanager chdir=/etc/rc2.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hive-metastore S85hive-metastore chdir=/etc/rc2.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hive-server2 S85hive-server2 chdir=/etc/rc2.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/impala-state-store S90impala-state-store chdir=/etc/rc2.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/impala-server S91impala-server chdir=/etc/rc2.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/impala-catalog S92impala-catalog chdir=/etc/rc2.d
  ignore_errors: True

- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hadoop-hdfs-namenode S85hadoop-hdfs-namenode chdir=/etc/rc3.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hadoop-hdfs-datanode S85hadoop-hdfs-datanode chdir=/etc/rc3.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hadoop-hdfs-secondarynamenode S85hadoop-hdfs-secondarynamenode chdir=/etc/rc3.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hadoop-yarn-resourcemanager S85hadoop-yarn-resourcemanager chdir=/etc/rc3.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hadoop-yarn-nodemanager S85hadoop-yarn-nodemanager chdir=/etc/rc3.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hive-metastore S85hive-metastore chdir=/etc/rc3.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hive-server2 S85hive-server2 chdir=/etc/rc3.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/impala-state-store S90impala-state-store chdir=/etc/rc3.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/impala-server S91impala-server chdir=/etc/rc3.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/impala-catalog S92impala-catalog chdir=/etc/rc3.d
  ignore_errors: True

- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hadoop-hdfs-namenode S85hadoop-hdfs-namenode chdir=/etc/rc4.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hadoop-hdfs-datanode S85hadoop-hdfs-datanode chdir=/etc/rc4.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hadoop-hdfs-secondarynamenode S85hadoop-hdfs-secondarynamenode chdir=/etc/rc4.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hadoop-yarn-resourcemanager S85hadoop-yarn-resourcemanager chdir=/etc/rc4.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hadoop-yarn-nodemanager S85hadoop-yarn-nodemanager chdir=/etc/rc4.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hive-metastore S85hive-metastore chdir=/etc/rc4.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hive-server2 S85hive-server2 chdir=/etc/rc4.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/impala-state-store S90impala-state-store chdir=/etc/rc4.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/impala-server S91impala-server chdir=/etc/rc4.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/impala-catalog S92impala-catalog chdir=/etc/rc4.d
  ignore_errors: True

- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hadoop-hdfs-namenode S85hadoop-hdfs-namenode chdir=/etc/rc5.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hadoop-hdfs-datanode S85hadoop-hdfs-datanode chdir=/etc/rc5.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hadoop-hdfs-secondarynamenode S85hadoop-hdfs-secondarynamenode chdir=/etc/rc5.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hadoop-yarn-resourcemanager S85hadoop-yarn-resourcemanager chdir=/etc/rc5.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hadoop-yarn-nodemanager S85hadoop-yarn-nodemanager chdir=/etc/rc5.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hive-metastore S85hive-metastore chdir=/etc/rc5.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/hive-server2 S85hive-server2 chdir=/etc/rc5.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/impala-state-store S90impala-state-store chdir=/etc/rc5.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/impala-server S91impala-server chdir=/etc/rc5.d
  ignore_errors: True
- name: Create a symoblic link for all Hadoop, Hive and Impala process
  sudo: yes
  command: ln -s ../init.d/impala-catalog S92impala-catalog chdir=/etc/rc5.d
  ignore_errors: True

- name: Create Bigtop directory
  command: mkdir -p /usr/lib/bigtop-utils
  sudo: yes
- name: Copy Bigtop dependency files
  command: cp /mnt/Impala/bigtop-detect-classpath /usr/lib/bigtop-utils/
  sudo: yes
- name: Copy Bigtop dependency files
  command: cp /mnt/Impala/bigtop-detect-javahome /usr/lib/bigtop-utils/
  sudo: yes
- name: Copy Bigtop dependency files
  command: cp /mnt/Impala/bigtop-detect-javalibs /usr/lib/bigtop-utils/
  sudo: yes
- name: Copy Bigtop dependency files
  command: cp /mnt/Impala/jsvc /usr/lib/bigtop-utils/
  sudo: yes

#delete hdfs directory
- name: Delete hdfs namenode dir
  command: rm -rf /mnt/Impala/testdata/cluster/cdh5/node-1/data/dfs/nn
  sudo: yes
- name: Delete hdfs datanode dir
  command: rm -rf /mnt/Impala/testdata/cluster/cdh5/node-1/data/dfs/dn
  sudo: yes
- name: format hdfs namenode
  command: /mnt/local/hadoop/bin/hdfs namenode -format

- name: Stop Hadoop namenode
  command: pkill -f "namenode"
  ignore_errors: True
  sudo: yes
- name: Start Hadoop namenode
  service: name=hadoop-hdfs-namenode state=started
  ignore_errors: True
  sudo: yes
- name: Stop Hadoop datanode
  command: pkill -f "datanode"
  ignore_errors: True
  sudo: yes
- name: Start Hadoop datanode
  service: name=hadoop-hdfs-datanode state=started
  ignore_errors: True
  sudo: yes
- name: Stop Hadoop secondarynamenode
  command: pkill -f "secondarynamenode"
  ignore_errors: True
  sudo: yes
- name: Start Hadoop secondarynamenode
  service: name=hadoop-hdfs-secondarynamenode state=started
  ignore_errors: True
  sudo: yes
- name: Stop Hadoop yarn resourcemanager
  command: pkill -f "resourcemanager"
  ignore_errors: True
  sudo: yes
- name: Start Hadoop yarn resourcemanager
  service: name=hadoop-yarn-resourcemanager state=started
  ignore_errors: True
  sudo: yes
- name: Stop Hadoop yarn nodemanager
  command: pkill -f "nodemanager"
  ignore_errors: True
  sudo: yes
- name: Start Hadoop yarn nodemanager
  service: name=hadoop-yarn-nodemanager state=started
  ignore_errors: True
  sudo: yes
- name: Stop Hive Metastore
  service: name=hive-metastore state=stopped
  ignore_errors: True
  sudo: yes
- name: Start Hive Metastore
  service: name=hive-metastore state=started
  ignore_errors: True
  sudo: yes
- name: Stop Hive Server2
  service: name=hive-server2 state=stopped
  ignore_errors: True
  sudo: yes
- name: Start Hive Server2
  service: name=hive-server2 state=started
  ignore_errors: True
  sudo: yes
- name: Stop Impala Statestore
  service: name=impala-state-store state=stopped
  ignore_errors: True
  sudo: yes
- name: Start Impala Statestore
  service: name=impala-state-store state=started
  ignore_errors: True
  sudo: yes
- name: Stop Impala Server
  service: name=impala-server state=stopped
  ignore_errors: True
  sudo: yes
- name: Start Impala Server
  service: name=impala-server state=started
  ignore_errors: True
  sudo: yes
- name: Stop Impala Catalog
  service: name=impala-catalog state=stopped
  ignore_errors: True
  sudo: yes
- name: Start Impala Catalog
  service: name=impala-catalog state=started
  ignore_errors: True
  sudo: yes
